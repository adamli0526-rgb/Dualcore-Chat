# DualCore Chat v1.0.0 — First Public Release 🚀

We’re excited to launch the first public release of **DualCore Chat**, a privacy-first desktop client for multiple AI models.

## ✨ Features
- **Multi-provider support**: Switch between OpenAI, Google Gemini, Anthropic Claude, Grok, and local Ollama.  
- **Local-only history**: All your chats are stored on your machine — no server required.  
- **License system**: 7-day free trial, then $9.99 one-time license.  
- **Cross-platform builds**:
  - Windows: `.msi` installer  
  - macOS: Universal `.dmg` (x64 + arm64, signed & notarized)  
  - Linux: `.AppImage`  

## 🛠 Improvements
- Auto-update support (Tauri updater).  
- Lightweight footprint (<10 MB binary, minimal RAM use).  
- Modern dark-themed UI with side navigation (Chat / Memory / Settings).  

## ⚠️ Known Issues
- Some Linux distros may require manual dependency installation (`libwebkit2gtk`).  
- Ollama (local models) requires Ollama to be installed and running separately.  

## 🔮 Roadmap
- Prompt library and templates  
- Team spaces with shared history  
- Offline RAG with local embeddings  

## 📥 Download
👉 [Download here](https://github.com/adamli0526-rgb/dualcore-chat)  

Thank you for trying **DualCore Chat**!
